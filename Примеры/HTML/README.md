В примерах используется [HtmlAgilityPack](https://html-agility-pack.net). Это парсер HTML. Вообще много что можно сделать. То, что представлено в примерах, это лишь малая часть того, что можно придумать. Поэтому рекомендую ознакомиться с **HtmlAgilityPack** получше.

Инициализация и загрузка файла html простая:

```c#
HtmlDocument doc = new();
doc.Load(context.FilePath);
```

Где `context.FilePath` - наименование файла html страницы.

Далее можно уже работать с `doc` и парсить как нам нужно.

Страницу можно сохранить с помощью сочетания клавиш `Control + S`. Это можно автоматизировать с помощью RPA.

Далее можно найти и получить файл простым способом:

```c#
var directory = new DirectoryInfo(context.DownloadFolder);
var file = directory.GetFiles("*.html")
                    .OrderByDescending(f => f.LastWriteTime)
                    .FirstOrDefault();
```

Где `DownloadFolder` - папка загрузки. *Если что, то в нормальном браузере можно настроить стандартный путь загрузки.*

Так же видим, что применяется фильтр `*.html` и сортировка по времени последней записи. Иначе по простому говоря, получаем последний файл с расширением `.html`.

Тут нужно учесть, что `file` может быть `null`, если файл не будет найден. Поэтому не забываем делать проверку:

```c#
if (file != null) {...}
```

Кстати, нужно понимать, что файл может быть сформирован не сразу, поэтому не нужно убирать паузу на переход к выполнению активити сценария. А в некоторых случаях возможно даже потребуется увеличить время ожидания. А иногда, возможно, даже стоит прибегнуть к ожидаю формирования таблицы в самом сценарии, используя цикл, но это уже скорее всего будет признаком, что машина имеет слишком малую производительность. Это же не какой-то большой файл, который не известно какого размера и может быть от пару МБ до пару ГБ, который может загружаться от пару секунд, до несколько часов, в зависимости от размера и скорости скачивания.

Полное имя файла можно получить так: `file.FullName`. Это мы можем сохранить в контекст при необходимости (и можно использовать потом сразу как в примере выше) или сразу использовать в этом же скрипте:

```C#
HtmlDocument doc = new();
doc.Load(file.FullName);
```

Для удобства мы можем выносить логику в отдельные методы. Мы можем использовать параметр типа `HtmlDocument`. А так же рекомендую использовать сразу ноды (тип `HtmlNode`), т.к. весь контекст html страницы состоит из нод и таким образом можно обобщить. А у `HtmlDocument` можно получить ноду так: `doc.DocumentNode`. В принципе можно не запариваться и использовать тип `HtmlDocument` в параметрах. Я даже постараюсь в примерах использовать хотя бы раз просто `HtmlDocument`, но в большинстве случаев я буду использовать `HtmlNode`. Но почему? Для обобщения логики. Для каких-то простых случаев мы можем просто сразу в одном методе искать на странице одну единственную таблицу по тегу `table`. Тут можно даже не запариваться и не создавать дополнительных методов. Но в более менее сложной обработке логичнее использовать везде `HtmlNode`. Так мы можем найти какую-то определенную ноду или даже несколько и отправлять в метод на дальнейшую обработку, а так же использовать этот же метод для все страницы, использовав корневую ноду `doc.DocumentNode`.

## SelectNodes и XPath

Далее немного напишем про метод **SelectNodes**. Этот метод часто может быть использован. Он позволяет получить дочерние ноды у ноды. На вход принимает **xpath** в виде строки (`string`) или выражения (`XPathExpression`). Пока не будем лезть в выражения (`XPathExpression`), а будем использовать более понятный вариант со строками. Вообще рекомендуется ознакомиться с **xpath** отдельно по подробнее, это будет очень полезно, т.к. в этом по сути вся сила будет для обработки данных. Но скорее всего частично, возможно, с xpath уже встречались при работе с ELMA RPA или других RPA продуктах. Метод **SelectNodes** возвращает коллекцию нодов (класс `HtmlNodeCollection`).

Пример получения нодов таблиц (`table`):

```c#
var tableNodes = document.DocumentNode.SelectNodes("//table");
```

Пример получения нодов строк таблицы (`tr`):

```c#
var nodes = document.DocumentNode.SelectNodes("//table/tr");
```

Или так (не забываем, что метод SelectNodes есть у `HtmlNode` и можно у любой ноды вызвать, не важно, что это будет корневая нода документа или мы до этого искали определенную ноду и послали ее, например, в метод, а также что структура таблицы может быть разной):

```c#
var nodes = node.SelectNodes("//table/*/tr");
```

XPath обладает большой мощностью. Мы можем получать определенные элементы в очень не простых структурах. Например, может выглядеть так:

```c#
var trNodes = node.SelectNodes("//div/div/table/tbody/tr");
```

Или как-то так:

```c#
var tableNodes = node.SelectNodes("//div[@id='divGridData']/div[2]/table");
```

Всё зависит от поставленной задачи и структуры страницы. Это действительно может быть очень функционально и удобно. Так что еще раз рекомендую поразобраться в XPath.

## Извлечение данных таблицы

В некоторых случаях нужно обработать таблицу на сайте. Т.к. верстка сайтов может быть очень специфической, ELMA RPA может не справиться или будет не очень удобно получать данные с таблиц.

В некоторых случаях очень нужна будет скорость обработки данных. Например, таблица имеет прямые ссылки на скачивание файлов. Задача: скачать все файлы из таблицы. Таблица очень большая и автоматизируя с помощью RPA может очень сильно медленно. Теряется время на поиск элементов, клики, анимации загрузки, ожидание загрузки файлов, закрытие панели загрузки и т.д. Это можно оптимизировать с помощью скрипта, разом найти все ссылки и в крипте скачать все файлы. Естественно, это может не всегда подойти. Если ссылка не прямая, а, например, создается js скриптом по нажатию, то такой вариант не прокатит. Такое, теоретически, тоже можно обработать в скрипте, но это уже будет приравниваться к какой-то "сложной" разработке, в которой нет смысла, если у нас есть RPA.

Как вариант можно сохранить всю страницу и обработать таблицу или даже несколько таблиц более специфически с помощью скрипта.

Выше в самом начале описано про **HtmlAgilityPack**. Сейчас сразу перейдем к конкретике по таблицам.

